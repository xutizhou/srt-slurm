# Current low latency config. Note that "2-mid-curve-pt1" has the ultra low latency points
# Obviously have much more work to do on low latency
# Decode uses TEP8 here with DP attention 4 (this was typo i need to rerun this without any dp attn and pobably use this for low latency as well)

name: "gb300-fp4-128k8k-5-low-latency"

model:
  path: "dsfp4"
  container: "ishandhanani/sglang:rt-cu13-yamy128k-full"
  precision: "fp4"

resources:
  decode_nodes: 2
  decode_workers: 2
  gpu_type: "gb300"
  gpus_per_node: 4
  prefill_nodes: 1
  prefill_workers: 1

backend:

  decode_environment:
    DYN_SKIP_SGLANG_LOG_FORMATTING: '1'
    FLASHINFER_DISABLE_VERSION_CHECK: '1'
    FLASHINFER_WORKSPACE_BASE: /configs/flashinfer-cache
    MC_FORCE_MNNVL: '1'
    NCCL_CUMEM_ENABLE: '1'
    NCCL_MNNVL_ENABLE: '1'
    PYTHONUNBUFFERED: '1'
    SGLANG_DECODE_BOOTSTRAP_TIMEOUT: '1000'
    SGLANG_DISABLE_TP_MEMORY_INBALANCE_CHECK: '1'
    SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT: '100000'
    SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE: '100000'
    SGLANG_DISAGGREGATION_WAITING_TIMEOUT: '100000'
    SGLANG_ENABLE_JIT_DEEPGEMM: 'false'
    SGLANG_FLASHINFER_FP4_GEMM_BACKEND: cutlass
    SGLANG_MOONCAKE_CUSTOM_MEM_POOL: 'True'
    SGLANG_USE_MESSAGE_QUEUE_BROADCASTER: '0'
    TORCH_DISTRIBUTED_DEFAULT_TIMEOUT: '1800'

  prefill_environment:
    DYN_SKIP_SGLANG_LOG_FORMATTING: '1'
    FLASHINFER_DISABLE_VERSION_CHECK: '1'
    FLASHINFER_WORKSPACE_BASE: /configs/flashinfer-cache
    MC_FORCE_MNNVL: '1'
    NCCL_CUMEM_ENABLE: '1'
    NCCL_MNNVL_ENABLE: '1'
    PYTHONUNBUFFERED: '1'
    SGLANG_DECODE_BOOTSTRAP_TIMEOUT: '1000'
    SGLANG_DISABLE_TP_MEMORY_INBALANCE_CHECK: '1'
    SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT: '100000'
    SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE: '100000'
    SGLANG_DISAGGREGATION_WAITING_TIMEOUT: '100000'
    SGLANG_ENABLE_JIT_DEEPGEMM: 'false'
    SGLANG_FLASHINFER_FP4_GEMM_BACKEND: cutlass
    SGLANG_MOONCAKE_CUSTOM_MEM_POOL: 'True'
    SGLANG_USE_MESSAGE_QUEUE_BROADCASTER: '0'
    TORCH_DISTRIBUTED_DEFAULT_TIMEOUT: '1800'

  sglang_config:
    decode:
      attention-backend: trtllm_mla
      chunked-prefill-size: -1
      context-length: 136000
      cuda-graph-max-bs: 256
      data-parallel-size: 4 # this was a typo when i ran i need to rerun this without dp attn
      disable-radix-cache: true
      disaggregation-bootstrap-port: 30001
      disaggregation-mode: decode
      disaggregation-transfer-backend: nixl
      enable-dp-attention: true # same here
      enable-symm-mem: true
      expert-parallel-size: 4
      kv-cache-dtype: fp8_e4m3
      mem-fraction-static: 0.95
      model-path: /model/
      moe-dense-tp-size: 1
      moe-runner-backend: flashinfer_trtllm
      pipeline-parallel-size: 1
      prefill-round-robin-balance: true
      quantization: modelopt_fp4
      scheduler-recv-interval: 1
      served-model-name: deepseek-ai/DeepSeek-R1
      stream-interval: 10
      tensor-parallel-size: 4
      trust-remote-code: true
      watchdog-timeout: 1000000

    prefill:
      attention-backend: trtllm_mla
      chunked-prefill-size: -1
      context-length: 136000
      data-parallel-size: 1
      disable-radix-cache: true
      disaggregation-bootstrap-port: 30001
      disaggregation-mode: prefill
      disaggregation-transfer-backend: nixl
      enable-symm-mem: true
      expert-parallel-size: 1
      kv-cache-dtype: fp8_e4m3
      load-balance-method: round_robin
      max-total-tokens: 544000
      mem-fraction-static: 0.95
      model-path: /model/
      moe-dense-tp-size: 1
      moe-runner-backend: flashinfer_trtllm
      pipeline-parallel-size: 4
      quantization: modelopt_fp4
      scheduler-recv-interval: 1
      served-model-name: deepseek-ai/DeepSeek-R1
      stream-interval: 10
      tensor-parallel-size: 1
      trust-remote-code: true
      watchdog-timeout: 1000000

benchmark:
  concurrencies: "16x32" # as i have said in other comments i might be able to use this for full low lat as well
  isl: 128000
  osl: 8000
  req_rate: "inf"
  type: "sa-bench"