name: "agg-tp-h200-fp8"

model:
  path: "dsr1"
  container: "lmsysorg/sglang:v0.5.8-cu130"
  precision: "fp8"

frontend:
  nginx_container: nginx

resources:
  gpu_type: "h200"
  agg_nodes: 1
  agg_workers: 1
  gpus_per_node: 8

backend:

  aggregated_environment:
    SGLANG_JIT_DEEPGEMM_FAST_WARMUP: "1"

  sglang_config:
    aggregated:
      # Model configuration
      served-model-name: "deepseek-ai/DeepSeek-R1"
      model-path: "/model/"
      skip-tokenizer-init: true
      trust-remote-code: true

      # Parallelism
      tp-size: 8
      dp-size: 1

      # KV cache and attention
      attention-backend: "flashinfer"

      # Radix cache disabled
      disable-radix-cache: true

      # Other flags
      stream-interval: 10
      watchdog-timeout: 1000000
      max-running-requests: 256  # sum of all dp

      # Memory and token limits
      mem-fraction-static: 0.82
      max-prefill-tokens: 32768
      chunked-prefill-size: 32768

      # CUDA graphs
      cuda-graph-max-bs: 256

benchmark:
  type: "sa-bench"
  isl: 8192
  osl: 1024
  concurrencies: "1x4x16x32x64x128x256"
  req_rate: "inf"

