name: "bs8-1p6d-h200-fp8-mtp"

model:
  path: "dsfp8"
  container: "lmsysorg/sglang:v0.5.8-cu130-runtime"
  precision: "fp8"

resources:
  gpu_type: "h200"
  prefill_nodes: 1
  prefill_workers: 1
  decode_nodes: 6
  decode_workers: 6
  gpus_per_node: 8

backend:

  # Prefill-specific environment variables
  prefill_environment:
    SGLANG_ENABLE_SPEC_V2: "1"
    SGLANG_JIT_DEEPGEMM_FAST_WARMUP: "1"
    SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE: "100000"
    SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT: "100000"
    SGLANG_DISAGGREGATION_WAITING_TIMEOUT: "100000"

  # Decode-specific environment variables
  decode_environment:
    SGLANG_ENABLE_SPEC_V2: "1"
    SGLANG_JIT_DEEPGEMM_FAST_WARMUP: "1"
    SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE: "100000"
    SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT: "100000"
    SGLANG_DISAGGREGATION_WAITING_TIMEOUT: "100000"

  sglang_config:
    prefill:
      # Model configuration
      served-model-name: "deepseek-ai/DeepSeek-R1"
      model-path: "/model/"
      skip-tokenizer-init: true
      trust-remote-code: true
      watchdog-timeout: 1000000

      # Parallelism
      tp-size: 8
      dp-size: 1
      ep-size: 1 

      # KV cache and attention
      attention-backend: "flashinfer"

      # Radix cache disabled
      disable-radix-cache: true

      # Other flags
      # stream-interval: 50
      max-running-requests: 16
      

      # Prefill-specific mode
      disaggregation-bootstrap-port: 30001
      disaggregation-mode: "prefill"
      disaggregation-transfer-backend: nixl

      # Memory and token limits
      mem-fraction-static: 0.82
      max-prefill-tokens: 32768
      chunked-prefill-size: 32768

      # Request handling
      load-balance-method: "round_robin"


    decode:
      # Model configuration
      served-model-name: "deepseek-ai/DeepSeek-R1"
      model-path: "/model/"
      skip-tokenizer-init: true
      trust-remote-code: true
      watchdog-timeout: 1000000

      # Parallelism
      tp-size: 8
      dp-size: 1
      ep-size: 1

      # KV cache and attention
      attention-backend: "flashinfer"

      # Other flags
      disable-radix-cache: true
      stream-interval: 10

      # Disagg
      disaggregation-bootstrap-port: 30001
      disaggregation-mode: "decode"
      disaggregation-transfer-backend: nixl

      # Memory and token limits
      mem-fraction-static: 0.82
      max-running-requests: 16
      cuda-graph-max-bs: 16

      # MTP settings
      speculative-algorithm: "EAGLE"
      speculative-num-steps: 2
      speculative-eagle-topk: 1
      speculative-num-draft-tokens: 3

benchmark:
  type: "sa-bench"
  isl: 8192
  osl: 1024
  concurrencies: "2x4x8x16x32"
  req_rate: "inf"
